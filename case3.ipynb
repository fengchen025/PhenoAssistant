{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fchen2/RDS/anaconda3/envs/llm/lib/python3.11/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/fchen2/RDS/anaconda3/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/fchen2/RDS/anaconda3/envs/llm/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/home/fchen2/RDS/anaconda3/envs/llm/lib/python3.11/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from agents import user_proxy, manager\n",
    "dataset_dir = './data/winter-wheat_nutri-defi-identify_dndww20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\n",
      "I have a set of images containing winter wheat plants in field. Can you identify the nutrient deficiencies in these plants?\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "To identify nutrient deficiencies in winter wheat plants from images, we can use image classification models trained to recognize various nutrient deficiency symptoms. Here is a step-by-step plan to achieve this:\n",
      "\n",
      "1. **Check Available Models**: First, we need to check if there are any pre-trained models available for image classification that can identify nutrient deficiencies in plants.\n",
      "\n",
      "2. **Inference with Pre-trained Model**: If a suitable model is available, we will use it to classify the images and identify nutrient deficiencies.\n",
      "\n",
      "3. **Finetune a Model (if needed)**: If no suitable pre-trained model is available, we may need to finetune a model using a dataset of images labeled with nutrient deficiencies.\n",
      "\n",
      "4. **Analyze Results**: Once the classification is done, we will analyze the results to identify the specific nutrient deficiencies in the winter wheat plants.\n",
      "\n",
      "Let's start by checking the available models for image classification.\n",
      "\n",
      "I'll proceed with step 1.\n",
      "\u001b[32m***** Suggested tool call (call_mqauVqer0GctguEqaoD2pAjx): get_model_zoo *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m******************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_model_zoo...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_mqauVqer0GctguEqaoD2pAjx) *****\u001b[0m\n",
      "{\"instance-segmentation\": [\"fengchen025/arabidopsis_leaf-instance-segmentation_cvppp2017-a1a4_m2fb_fullft\", \"potato_leaf-instance-segmentation_leaf-only-sam\"], \"image-classification\": [], \"image-regression\": []}\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "It appears that there are no pre-trained models available specifically for image classification of nutrient deficiencies in plants.\n",
      "\n",
      "Given this, we have two options:\n",
      "1. **Finetune a Model**: We can finetune an image classification model using a dataset of images labeled with nutrient deficiencies.\n",
      "2. **Suggest Dataset Preparation**: If you have a dataset of images with labeled nutrient deficiencies, we can prepare and use it for finetuning a model.\n",
      "\n",
      "Please let me know if you have a labeled dataset for nutrient deficiencies in winter wheat plants, or if you would like guidance on how to prepare such a dataset.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "I would like guidance on preparing a dataset\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_8k0Tx0afHh032KIBNCcSloYZ): get_dataset_format *****\u001b[0m\n",
      "Arguments: \n",
      "{\"task\":\"image-classification\"}\n",
      "\u001b[32m***********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_dataset_format...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_8k0Tx0afHh032KIBNCcSloYZ) *****\u001b[0m\n",
      "\n",
      "dataset_name/\n",
      "│\n",
      "├── train/ # folder containing training images and labels\n",
      "│   ├── metadata.csv # must include columns of \"file_name\" (image file names) and \"label\" (corresponding label names for each image)\n",
      "│   ├── 1.jpg # training image 1\n",
      "│   ├── 2.jpg # training image 2\n",
      "│   └── ...\n",
      "│\n",
      "├── test/ # (Optional) folder containing test images and labels\n",
      "│   ├── metadata.csv # must include \"file_name\" column\n",
      "│   ├── 1.jpg # test image 1\n",
      "│   ├── 2.jpg # test image 2  \n",
      "│   └── ...\n",
      "│\n",
      "├── label2id.json # dictionary mapping label names to numerical IDs, e.g., {\"Healthy\": 0, \"Unhealthy\": 1}\n",
      "\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "To prepare a dataset for finetuning an image classification model, you need to organize your images and labels in the following structure:\n",
      "\n",
      "```\n",
      "dataset_name/\n",
      "│\n",
      "├── train/ # folder containing training images and labels\n",
      "│   ├── metadata.csv # must include columns of \"file_name\" (image file names) and \"label\" (corresponding label names for each image)\n",
      "│   ├── 1.jpg # training image 1\n",
      "│   ├── 2.jpg # training image 2\n",
      "│   └── ...\n",
      "│\n",
      "├── test/ # (Optional) folder containing test images and labels\n",
      "│   ├── metadata.csv # must include \"file_name\" column\n",
      "│   ├── 1.jpg # test image 1\n",
      "│   ├── 2.jpg # test image 2  \n",
      "│   └── ...\n",
      "│\n",
      "├── label2id.json # dictionary mapping label names to numerical IDs, e.g., {\"Healthy\": 0, \"Unhealthy\": 1}\n",
      "```\n",
      "\n",
      "### Steps to Prepare the Dataset:\n",
      "\n",
      "1. **Organize Images**:\n",
      "   - Place all training images in the `train/` folder.\n",
      "   - Optionally, place test images in the `test/` folder.\n",
      "\n",
      "2. **Create Metadata Files**:\n",
      "   - In the `train/` folder, create a `metadata.csv` file with two columns: `file_name` and `label`. Each row should correspond to an image file and its label.\n",
      "   - In the `test/` folder (if you have test images), create a `metadata.csv` file with one column: `file_name`.\n",
      "\n",
      "3. **Create Label Mapping**:\n",
      "   - Create a `label2id.json` file in the root directory. This file should map label names to numerical IDs. For example:\n",
      "     ```json\n",
      "     {\n",
      "       \"Healthy\": 0,\n",
      "       \"Nitrogen Deficiency\": 1,\n",
      "       \"Phosphorus Deficiency\": 2,\n",
      "       \"Potassium Deficiency\": 3,\n",
      "       ...\n",
      "     }\n",
      "     ```\n",
      "\n",
      "Once you have prepared the dataset in this format, please upload it, and we can proceed with finetuning the image classification model to identify nutrient deficiencies in winter wheat plants.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "I already upload a dataset at ./data/winter-wheat_nutri-defi-identify_dndww20, please start training.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_bGFkPv7IioNvyWm97fRB3nNa): prepare_dataset *****\u001b[0m\n",
      "Arguments: \n",
      "{\"dataset_name\":\"winter-wheat_nutri-defi-identify_dndww20\",\"root\":\"./data/winter-wheat_nutri-defi-identify_dndww20\",\"task\":\"classification\"}\n",
      "\u001b[32m********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION prepare_dataset...\u001b[0m\n",
      "Dataset 'winter-wheat_nutri-defi-identify_dndww20' does not exist. Proceed to create the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 1332/1332 [00:00<00:00, 36919.54 examples/s]\n",
      "Map: 100%|██████████| 468/468 [00:00<00:00, 50784.80 examples/s]\n",
      "Casting the dataset: 100%|██████████| 468/468 [00:00<00:00, 265692.24 examples/s]\n",
      "Map: 100%|██████████| 666/666 [00:18<00:00, 36.03 examples/s]?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 7/7 [00:00<00:00, 19.48ba/s]\n",
      "Map: 100%|██████████| 666/666 [00:17<00:00, 37.15 examples/s]53, 53.23s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 7/7 [00:00<00:00, 18.33ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 2/2 [01:47<00:00, 53.91s/it]\n",
      "Map: 100%|██████████| 468/468 [00:13<00:00, 34.22 examples/s]?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 18.48ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:40<00:00, 40.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_bGFkPv7IioNvyWm97fRB3nNa) *****\u001b[0m\n",
      "The dataset has been uploaded to HuggingFace as 'winter-wheat_nutri-defi-identify_dndww20'.\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_AXjKqInpUHuWr4U6yastq9wW): finetune_image_classification *****\u001b[0m\n",
      "Arguments: \n",
      "{\"dataset_name\":\"winter-wheat_nutri-defi-identify_dndww20\",\"ft_method\":\"lora\",\"train_bs\":32,\"val_bs\":1,\"img_w\":512,\"img_h\":512,\"lr\":0.0001,\"epochs\":1}\n",
      "\u001b[32m**********************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_AXjKqInpUHuWr4U6yastq9wW) *****\u001b[0m\n",
      "USER INTERRUPTED\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "what finetuning methods do you provide?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "I provide the following finetuning methods for image classification models:\n",
      "\n",
      "1. **LoRA (Low-Rank Adaptation)**: This method adapts the pre-trained model by learning low-rank updates, which is computationally efficient and requires less memory.\n",
      "\n",
      "2. **Full Fine-Tuning (FullFT)**: This method involves fine-tuning all the parameters of the pre-trained model, which can be more computationally intensive but may yield better performance for some tasks.\n",
      "\n",
      "Please let me know which finetuning method you would like to use, and I will proceed with the training.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "let's do lora\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_5x6lqzDLk2aBPBDZjvz8DiyA): finetune_image_classification *****\u001b[0m\n",
      "Arguments: \n",
      "{\"dataset_name\":\"winter-wheat_nutri-defi-identify_dndww20\",\"ft_method\":\"lora\",\"train_bs\":32,\"val_bs\":1,\"img_w\":512,\"img_h\":512,\"lr\":0.0001,\"epochs\":1}\n",
      "\u001b[32m**********************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION finetune_image_classification...\u001b[0m\n",
      "Model 'winter-wheat_nutri-defi-identify_dndww20_dino2b_lora' does not exist. Proceed to train the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 1332/1332 [00:08<00:00, 154.64 examples/s]\n",
      "Generating test split: 100%|██████████| 468/468 [00:03<00:00, 138.97 examples/s] \n",
      "Some weights of Dinov2ForImageClassification were not initialized from the model checkpoint at facebook/dinov2-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 86591239 || all params: 86591239 || trainable%: 100.00\n",
      "trainable params: 324103 || all params: 86896910 || trainable%: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfeng-chen\u001b[0m (\u001b[33mfeng_edin\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/remote/rds/users/fchen2/codes/PhenoAssistant_Github/wandb/run-20250408_114259-zefxyb8e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/feng_edin/huggingface/runs/zefxyb8e' target=\"_blank\">winter-wheat_nutri-defi-identify_dndww20_dino2b_lora</a></strong> to <a href='https://wandb.ai/feng_edin/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/feng_edin/huggingface' target=\"_blank\">https://wandb.ai/feng_edin/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/feng_edin/huggingface/runs/zefxyb8e' target=\"_blank\">https://wandb.ai/feng_edin/huggingface/runs/zefxyb8e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fchen2/RDS/anaconda3/envs/llm/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2499, 'grad_norm': 9.269259452819824, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.8333333333333334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fchen2/RDS/anaconda3/envs/llm/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9868139028549194, 'eval_accuracy': 0.16417910447761194, 'eval_runtime': 6.2792, 'eval_samples_per_second': 21.34, 'eval_steps_per_second': 3.185, 'epoch': 1.0}\n",
      "{'train_runtime': 55.1387, 'train_samples_per_second': 21.727, 'train_steps_per_second': 0.109, 'train_loss': 2.2276655038197837, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model added to model_zoo successfully!\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_5x6lqzDLk2aBPBDZjvz8DiyA) *****\u001b[0m\n",
      "Best validation accuracy is 0.16417910447761194.\n",
      " The trained model is saved as fengchen025/winter-wheat_nutri-defi-identify_dndww20_dino2b_lora in model zoo.\n",
      "Full details of the trained model can be found in the model card:\n",
      "---\n",
      "library_name: peft\n",
      "license: apache-2.0\n",
      "base_model: facebook/dinov2-base\n",
      "tags:\n",
      "- image-classification\n",
      "- vision\n",
      "- generated_from_trainer\n",
      "metrics:\n",
      "- accuracy\n",
      "model-index:\n",
      "- name: winter-wheat_nutri-defi-identify_dndww20_dino2b_lora\n",
      "  results: []\n",
      "---\n",
      "\n",
      "<!-- This model card has been generated automatically according to the information the Trainer had access to. You\n",
      "should probably proofread and complete it, then remove this comment. -->\n",
      "\n",
      "# winter-wheat_nutri-defi-identify_dndww20_dino2b_lora\n",
      "\n",
      "This model is a fine-tuned version of [facebook/dinov2-base](https://huggingface.co/facebook/dinov2-base) on the winter-wheat_nutri-defi-identify_dndww20 dataset.\n",
      "It achieves the following results on the evaluation set:\n",
      "- Loss: 1.9868\n",
      "- Accuracy: 0.1642\n",
      "\n",
      "## Model description\n",
      "\n",
      "More information needed\n",
      "\n",
      "## Intended uses & limitations\n",
      "\n",
      "More information needed\n",
      "\n",
      "## Training and evaluation data\n",
      "\n",
      "More information needed\n",
      "\n",
      "## Training procedure\n",
      "\n",
      "### Training hyperparameters\n",
      "\n",
      "The following hyperparameters were used during training:\n",
      "- learning_rate: 0.0001\n",
      "- train_batch_size: 224\n",
      "- eval_batch_size: 7\n",
      "- seed: 42\n",
      "- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08\n",
      "- lr_scheduler_type: linear\n",
      "- num_epochs: 1\n",
      "\n",
      "### Training results\n",
      "\n",
      "| Training Loss | Epoch | Step | Validation Loss | Accuracy |\n",
      "|:-------------:|:-----:|:----:|:---------------:|:--------:|\n",
      "| 2.2499        | 1.0   | 6    | 1.9868          | 0.1642   |\n",
      "\n",
      "\n",
      "### Framework versions\n",
      "\n",
      "- PEFT 0.13.2\n",
      "- Transformers 4.45.2\n",
      "- Pytorch 2.4.1\n",
      "- Datasets 3.0.1\n",
      "- Tokenizers 0.20.1.\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "The model has been successfully fine-tuned using the LoRA method. The trained model is saved as `fengchen025/winter-wheat_nutri-defi-identify_dndww20_dino2b_lora` in the model zoo.\n",
      "\n",
      "### Model Details:\n",
      "- **Base Model**: facebook/dinov2-base\n",
      "- **Training Loss**: 2.2499\n",
      "- **Validation Loss**: 1.9868\n",
      "- **Accuracy**: 0.1642\n",
      "- **Training Hyperparameters**:\n",
      "  - Learning Rate: 0.0001\n",
      "  - Train Batch Size: 224\n",
      "  - Eval Batch Size: 7\n",
      "  - Optimizer: Adam\n",
      "  - Number of Epochs: 1\n",
      "\n",
      "### Next Steps:\n",
      "1. **Inference**: We can now use this fine-tuned model to classify the images and identify nutrient deficiencies in the winter wheat plants.\n",
      "2. **Analysis**: Analyze the classification results to determine the specific nutrient deficiencies.\n",
      "\n",
      "Would you like to proceed with the inference on your images using this fine-tuned model? If so, please provide the path to the images.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Task: identifying nutrient deficiencies (train for 1 epoch as demonstration)\n",
    "task = '''\n",
    "I have a set of images containing winter wheat plants in field. Can you identify the nutrient deficiencies in these plants?\n",
    "'''\n",
    "res = user_proxy.initiate_chat(recipient=manager, message=task,)\n",
    "\n",
    "prompt1 = '''\n",
    "I would like guidance on preparing a dataset.\n",
    "'''\n",
    "\n",
    "prompt2 = f'''\n",
    "I already upload a dataset at {dataset_dir}, please start training.\n",
    "'''\n",
    "\n",
    "prompt3 = '''\n",
    "what finetuning methods do you provide?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\n",
      "What models are available in your vision model zoo?\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_HCpzgXWnt16rlyiOnQBpvEbK): get_model_zoo *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m******************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_model_zoo...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[33mAdmin\u001b[0m (to manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_HCpzgXWnt16rlyiOnQBpvEbK) *****\u001b[0m\n",
      "{\"instance-segmentation\": [\"fengchen025/arabidopsis_leaf-instance-segmentation_cvppp2017-a1a4_m2fb_fullft\", \"potato_leaf-instance-segmentation_leaf-only-sam\"], \"image-classification\": [\"fengchen025/winter-wheat_nutri-defi-identify_dndww20_dino2b_lora\"], \"image-regression\": []}\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmanager\u001b[0m (to Admin):\n",
      "\n",
      "The available models in the vision model zoo are:\n",
      "\n",
      "### Instance Segmentation:\n",
      "1. **fengchen025/arabidopsis_leaf-instance-segmentation_cvppp2017-a1a4_m2fb_fullft**\n",
      "2. **potato_leaf-instance-segmentation_leaf-only-sam**\n",
      "\n",
      "### Image Classification:\n",
      "1. **fengchen025/winter-wheat_nutri-defi-identify_dndww20_dino2b_lora**\n",
      "\n",
      "### Image Regression:\n",
      "- No models available.\n",
      "\n",
      "If you need to use any of these models or require further assistance, please let me know!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check if the model zoo is updated with the trained model\n",
    "task = '''\n",
    "What models are available in your vision model zoo?\n",
    "'''\n",
    "res = user_proxy.initiate_chat(recipient=manager, message=task,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
