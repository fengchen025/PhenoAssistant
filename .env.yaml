# To run demo.ipynb, you must have an API key to set up an OpenAI LLM. There are two options:
#   1. Set API_TYPE to "openai". Set OPENAI_API_KEY to your OpenAI API key, and MODEL_NAME to the model you want to use.
#   2. Set API_TYPE to "azure". Set AZURE_API_KEY to your Azure API key; you will also need to set up the AZURE_API_VERSION, AZURE_API_URL, and MODEL_NAME given your deployment/endpoint on Azure.
# You can keep all the other environmental variables as they are (Note: if you don't set up HuggingFace token/user (HF_TOKEN/HF_USER), RAG and other functions may be disabled, but these are not at demo.ipynb)

API_TYPE: "azure" # azure or openai
MODEL_NAME: # e.g. gpt-4o (for azure it is the deployment name)
OPENAI_API_KEY: # your openai/azure key
AZURE_API_VERSION: # for azure
AZURE_API_URL: # for azure

HF_TOKEN:  # read/write/access huggingface token
HF_USER: # huggingface user name
HF_HOME: # huggingface local cache
HF_DATASETS_CACHE: # huggingface local dataset cache
TRANSFORMERS_CACHE: # huggingface local model cache
PANDASAI_API_KEY: # pandas ai api key
MODEL_ZOO: './model_zoo.json'
PIPELINE_ZOO: './pipeline_zoo.json' # registration
PIPELINE_PATH: './extracted_pipelines.py' # actual extracted pipelines
